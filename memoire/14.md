# Annexe A — Modèles de livrables (templates)

Les modèles ci‑dessous sont fournis à titre indicatif. Ils visent à standardiser la traçabilité, faciliter la validation par la maîtrise d'ouvrage, et produire des preuves claires (tests, déploiements, décisions). Le titulaire s'adapte à l'outillage retenu par le Service Central Vigicrues (SCV).

---

## Légende et conventions

- Sigles : **ME** (maintenance évolutive), **MC** (maintenance corrective), **HD** (haute disponibilité), **VA** (vérification d'aptitude), **VSR** (vérification de service régulier), **SCV** (Service Central Vigicrues), **SPC GD** (maîtrise d'œuvre).
- Criticité (si utilisée) : **C** = critique (service indisponible / risque données), **M** = majeure (fonction clé dégradée), **m** = mineure (gêne sans impact majeur).

## A.1 Note de livraison (livraison complète / mise à jour)

### Métadonnées
- Marché : `MF_2025_TMA_AQUAREEL`
- Livraison : `[complète | mise à jour]`
- Version : `[X.Y.Z]`
- Date : `[JJ/MM/AAAA]`
- Référence(s) ticket(s) : `[TICKET-123, ...]`
- Prestation : `[ME | MC | exploitation]`
- Environnement(s) cible(s) : `[site actif / passif / surveillance | instance(s) concernée(s)]`
- Prérequis : `[versions, fenêtres, accès, sauvegardes]`
- Contact titulaire : `[téléphone / email]`

### 1) Résumé exécutif
- Objectif : `[1–3 lignes]`
- Impact : `[fonctionnel / technique / HD]`
- Risques / points de vigilance : `[liste courte]`

### 2) Contenu de la livraison
| Ticket | Type | Description | Composants | Commentaire |
|--------|------|-------------|------------|-------------|
| `[TICKET-123]` | `[MC/ME]` | `[texte]` | `[SQL / services / clients]` | `[texte]` |

### 3) Scripts, packages et documentation fournis
- Scripts SQL : `[liste]`
- Setup / package : `[liste]`
- Procédure d'installation : `[fichier / lien]`
- Procédure de rollback : `[fichier / lien]`
- Documentation mise à jour : `[manuel exploitation / installation / utilisateur / modèle]`
- Empreintes d'intégrité : `SHA‑256` `[liste]`

### 4) Plan de déploiement (résumé)
1. `[Étape 1]`
2. `[Étape 2]`
3. `[Étape 3]`

### 5) Plan de rollback (résumé)
- Conditions de déclenchement : `[ex. erreur réplication, incident critique, validation impossible]`
- Procédure : `[étapes]`
- Vérifications post‑rollback : `[étapes]`

### 6) Tests et validation
- Rapport de tests de non‑régression joint : `[oui/non]` (cf. Annexe A.2)
- Points de contrôle HD (si applicable) : `[réplication, bascule, supervision]`
- Instructions de validation : `[VA / VSR / contrôles]`
- Décision Go/No‑Go (avant MEP) : `[GO/NO‑GO]` — Validée par : `[MOE/SCV]` — Date : `[JJ/MM/AAAA]`

### 7) Surveillance post‑déploiement
- À surveiller : `[logs, réplication, alarmes, latence, jobs]`
- Fenêtre de surveillance recommandée : `[durée]`

---

## A.2 Rapport de tests de non‑régression (base + applicatif)

### Métadonnées
- Version testée : `[X.Y.Z]`
- Date : `[JJ/MM/AAAA]`
- Environnement de test : `[plateforme test HD du titulaire | Privas si radio]`
- Jeu de données de référence : `[identifiant / version]`
- Référence(s) ticket(s) : `[TICKET-...]`

### 1) Synthèse
| Indicateur | Valeur |
|-----------|--------|
| Tests exécutés | `[N]` |
| Réussis | `[N]` |
| Échoués | `[N]` |
| Bloquants | `[N]` |
| Durée totale | `[hh:mm]` |

### 1bis) Baselines & écarts (optionnel)
- Baseline prise en compte : `[ex. Q/R n°6 : requêtes volumineuses ~3s]`
- Mesures réalisées : `[p50/p95, temps de chargement, traitements batch]`
- Écarts notables / décisions : `[liste]`

### 2) Périmètre des tests
- SQL : `[procédures / triggers / jobs / vues]`
- Applicatif : `[services / clients / collecte]`
- Haute disponibilité : `[réplication / bascule / supervision]`
- Interfaces réelles : `[stations, modems, LoRaWAN, exports]`

### 3) Résultats détaillés
| Cas de test | Nature | Résultat | Commentaire | Ticket / décision |
|------------|--------|----------|-------------|-------------------|
| `[T-NR-001]` | `[SQL]` | `[OK/KO]` | `[texte]` | `[TICKET-...]` |

### 4) Écarts et arbitrages
- Écart(s) connu(s) / accepté(s) : `[liste]`
- Décisions : `[référence RD / COPIL]`

### 5) Contrôles HD (si applicable)
- État réplication : `[OK/KO]` (erreurs : `[liste]`)
- Latence (ordre de grandeur) : `[valeur]`
- Test bascule : `[OK/KO]`
- Supervision : `[OK/KO]`

### 6) Annexes
- Logs / captures / exports : `[liste]`
- Commandes / scripts utilisés : `[liste]`
- Commande / script de génération du rapport : `[ex. script CI, commande, version]`

---

## A.3 Rapport d'intervention urgente

### Métadonnées
- Ticket : `[TICKET-...]`
- Date / heure : `[début] → [fin]`
- Instance : `[site / SPC / CVH]`
- Symptomatologie : `[texte]`

### Horodatage (preuve des délais)
| Point de passage | Date/heure |
|---|---|
| Alerte reçue | `[JJ/MM hh:mm]` |
| Prise en charge | `[JJ/MM hh:mm]` |
| Diagnostic posé | `[JJ/MM hh:mm]` |
| Service rétabli | `[JJ/MM hh:mm]` |
| Clôture / RD | `[JJ/MM hh:mm]` |

### 1) Diagnostic
- Reproduction / constats : `[texte]`
- Qualification : `[application | environnement (réseaux, périphériques, OS, supervision)]`
- Cause racine (si connue) : `[texte]`

### 2) Actions réalisées
- `[action 1]`
- `[action 2]`

### 3) Résultats et vérifications
- Tests / contrôles : `[texte]`
- Service rétabli : `[oui/non]`

### 4) Suite
- Contournement provisoire : `[si applicable]`
- Correction définitive : `[piste / besoin bon de commande]`
- Recommandations : `[texte]`

---

## A.4 Rapport d'audit périodique

### Métadonnées
- Instance auditée : `[site / SPC / CVH]`
- Date : `[JJ/MM/AAAA]`
- Périmètre : `[versions, maintenance BDD, supervision, HD]`

### 1) Synthèse exécutive
- Points critiques : `[liste]`
- Actions recommandées : `[liste]`

### 2) Constats détaillés
| Domaine | Constat | Criticité | Recommandation | Action réalisée |
|---------|---------|-----------|----------------|-----------------|
| `[BDD]` | `[texte]` | `[C/M/m]` | `[texte]` | `[oui/non]` |

### 3) Plan d'actions
- `[action]` → `[responsable]` → `[échéance]`

---

## A.5 Retour d'expérience (RCA) — anomalies bloquantes / majeures

### Métadonnées
- Incident / ticket : `[TICKET-...]`
- Période : `[début] → [fin]`
- Impact : `[collecte / export / HD / supervision]`

### 1) Chronologie
| Date/heure | Événement |
|-----------|-----------|
| `[JJ/MM hh:mm]` | `[texte]` |

### 2) Cause racine et facteurs contributifs
- Cause racine : `[texte]`
- Facteurs : `[texte]`

### 3) Remédiation et prévention
- Correction : `[texte]`
- Actions préventives : `[texte]`
- Tests ajoutés / enrichis : `[référence cas de test]`
- Documentation mise à jour : `[liste]`

### 4) Suivi
- Statut : `[clos/en cours]`
- Actions restantes : `[liste]`

---

## A.6 Tableau de bord hebdomadaire / COPIL mensuel (template)

### 1) Synthèse
- Période : `[Semaine/Mois]`
- Points clés : `[3–5 puces]`
- Risques / alertes : `[liste courte]`

### 2) Indicateurs
| KPI | Valeur | Tendance | Commentaire |
|-----|--------|----------|-------------|
| Taux de respect du délai d'intervention (urgences) | `[x%]` | `[↗/↘/=]` | `[texte]` |
| Délai de qualification | `[x j]` | `[↗/↘/=]` | `[texte]` |
| Tickets ouverts/clos | `[x/y]` | `[↗/↘/=]` | `[texte]` |
| Forfait support consommé | `[x j / 15]` | `[↗/↘/=]` | `[texte]` |

### 3) Backlog & priorités
- Top priorités : `[liste]`
- Tickets à risque : `[liste]`

### 4) Décisions / arbitrages
- `[décision]` (référence RD/COPIL : `[id]`)

---

## A.7 Rapport annuel de politique environnementale numérique (CCTP §7)

### Métadonnées
- Année de référence : `[N-1]`
- Date de remise : `[JJ/MM/AAAA]` (avant la fin du premier trimestre de l'année N)
- Périmètre : `TMA AQUAREEL` (prestations réalisées, outillage, pratiques internes liées au projet)

### Contenu attendu (structure proposée)
1. **Synthèse** (actions menées, points notables, plan d'amélioration)
2. **Sobriété numérique** (écoconception, optimisation requêtes/ressources, mesures qualitatives/quantitatives)
3. **Matériel et usage** (durée de vie, réemploi, environnement de travail)
4. **Indicateurs** (au choix : latence, poids pages, requêtes, conso ressources, etc.)
5. **Plan d'actions N+1**

### Formations (CCTP §7)
- Formations réalisées (dont écoconception / numérique responsable) : `[liste, dates, durées]`
- Sensibilisation interne / bonnes pratiques appliquées : `[liste]`

### Labels / certifications numériques (CCTP §7)
- Labels/certifications obtenus : `[aucun | liste]`
- Actions menées dans ce cadre ayant un impact sur Aquaréel : `[liste]`

### Indicateurs possibles (exemples)
Les Q/R du DCE indiquent qu'il n'y a pas d'attentes imposées : le titulaire propose une réponse **qualitative et/ou quantitative** adaptée.  
Exemples d'indicateurs (à sélectionner selon les moyens de mesure disponibles) :
- Application : `[p95 temps de réponse]`, `[nombre de requêtes par écran]`, `[taille des payloads]`, `[poids pages]`
- Base de données : `[temps exécution requêtes représentatives]`, `[index manquants/inefficaces]`, `[volume de données traité par traitement]`
- Infrastructure : `[CPU/RAM service collecte]`, `[taille base glissante]`, `[durées jobs]`

### Actions du titulaire (exemples)
- Écoconception logicielle dès la conception : optimisation des requêtes, limitation des transferts, sobriété des traitements.
- Poste de travail : utilisation d'un matériel réemployé et durable (ordinateur ancien), maintenance logicielle avec une distribution légère (Arch Linux).

---

## A.8 Action d'insertion / action sociale (CCAP §4.5)

### Fiche action (annuelle)
- Option retenue : `[heures d'insertion | 1 action d'insertion/an]`
- Action réalisée : `[session 3h | parrainage | immersion/stage | sensibilisation 3h | autre action sociale validée]`
- Exemple (si "autre action sociale validée") : `don annuel à une association locale (ex. Nice Volley Ball)`
- Validation facilitateur : `[oui/non]` — Référence : `[mail/CR]`
- Date / lieu / participants : `[texte]`
- Public concerné / structure : `[texte]`
- Partenaire / hôte (optionnel) : `[association / club / structure]`
- Attestation / justificatif : `[fichier]`

### Détail de l'action (si session 3h / sensibilisation)
- Objectifs : `[découverte métiers / remise à niveau / orientation]`
- Format : `[session de sensibilisation validée par le facilitateur | co‑animation | table ronde]`
- Intervenant(s) : `[titulaire + partenaires]`
- Programme (exemple) :
  1. Présentation des métiers (data/SQL/numérique) et des parcours
  2. Atelier compétences : CV / expérience / transférables
  3. Atelier pratique : compréhension d'une base, requêtes simples, qualité des données (adapté au public)
  4. Questions / réponses + orientation vers structures d'accompagnement
- Supports fournis : `[slides / fiche métiers / ressources]`
- Feuille d'émargement : `[oui/non]`

### Suivi mensuel (conformément au CCAP)
- Période couverte : `[mois]`
- Justificatifs transmis : `[oui/non]` — Date d'envoi : `[JJ/MM/AAAA]` (avant le 12 du mois suivant)
- Interlocuteur facilitateur (CCAP §4.5.3) : `csoccitanie@nova-emploi.fr — 06 17 67 43 34`
- Référent clause d'insertion (titulaire) : `Hadrien BLANC — contact@hadrienblanc.com — 07 83 77 52 44`

### Bilan
- Bilan périodique : `[oui/non]` — Date : `[JJ/MM/AAAA]`
- Bilan final : `[oui/non]` — Date : `[JJ/MM/AAAA]` (dans les 3 mois suivant la fin du marché)

---

## A.9 Relevé de décisions (réunion hebdo / COPIL)

### Métadonnées
- Date : `[JJ/MM/AAAA]` — Durée : `[hh:mm]` — Format : `[visio / présentiel]`
- Objet : `[hebdo suivi / COPIL / point technique]`
- Participants : `[SCV, SPC GD, titulaire, autres]`
- Référence(s) : `[tickets, versions, livraisons]`
- Envoi du relevé : `[JJ/MM/AAAA]` (≤ 5 jours ouvrés)
- Date limite retours : `[JJ/MM/AAAA]` (≤ 5 jours ouvrés)
- Intégration des remarques : `[JJ/MM/AAAA]` (≤ 24h)

### 1) Synthèse
- Points marquants : `[3–5 puces]`
- Alertes / risques : `[liste courte]`

### 2) Décisions et arbitrages
| Décision | Contexte | Responsable validation | Échéance |
|---|---|---|---|
| `[texte]` | `[texte]` | `[SCV/MOE]` | `[JJ/MM]` |

### 3) Actions
| Action | Responsable | Échéance | Ticket |
|---|---|---|---|
| `[texte]` | `[SCV/MOE/titulaire]` | `[JJ/MM]` | `[TICKET-...]` |

---

## A.10 Cahier de recette (VA / VSR) — plan de tests

### Métadonnées
- Version : `[X.Y.Z]`
- Type : `[VA | VSR]`
- Environnement : `[site / plateforme]`
- Périmètre : `[fonctionnel / technique / HD]`
- Pré‑requis : `[données, accès, sauvegarde]`

### 1) Critères d'entrée / sortie
- Critères d'entrée : `[liste]`
- Critères de sortie : `[ex. absence bloquante/majeure ; anomalies mineures documentées]`

### 2) Cas de tests
| ID | Objectif | Étapes | Résultat attendu | Statut | Ticket |
|---|---|---|---|---|---|
| `[REC-001]` | `[texte]` | `[texte]` | `[texte]` | `[OK/KO]` | `[TICKET-...]` |

### 3) Synthèse & PV
- Bilan : `[OK/KO]`
- PV / réserves : `[texte]`
- Signatures (si applicable) : `[MOE/SCV]`
- Notification : `[email + AR]` — Date : `[JJ/MM/AAAA]`

---

## A.11 Journal des corrections (garantie + maintenance corrective)

### Métadonnées
- Période couverte : `[JJ/MM/AAAA] → [JJ/MM/AAAA]`
- Source : `[export plateforme de suivi | registre titulaire]`
- Format : `[CSV/XLSX/PDF]`

### Journal
| Date | Ticket | Régime | Livraison / version | Nature | Résumé | Validation / preuve |
|---|---|---|---|---|---|---|
| `[JJ/MM/AAAA]` | `[TICKET-...]` | `[garantie/MC]` | `[X.Y.Z]` | `[SQL / service / client / config]` | `[texte]` | `[rapport tests / VA / VSR / PV]` |
